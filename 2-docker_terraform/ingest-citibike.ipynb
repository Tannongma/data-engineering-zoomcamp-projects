{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e9c09b-7a2c-4a6e-8745-24079b2ee74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7dd28f-cdf3-4200-aba0-8f9e3c857333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inmport necessary libraries\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import subprocess\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd070c43-776f-4c9b-bfd6-33ad32a8e16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__#!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3140850a-64ed-4c33-a562-f17242eaec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_URL = \"https://s3.amazonaws.com/tripdata/\"\n",
    "\n",
    "def scrape_citibike_files():\n",
    "    xml_index_url = BASE_URL\n",
    "    response = requests.get(xml_index_url)\n",
    "    links = list()\n",
    "    soup = BeautifulSoup(response.text, features=\"xml\")\n",
    "    xml_keys = soup.find_all('Key')\n",
    "\n",
    "    # Extract all download links\n",
    "    files = [urljoin(BASE_URL, str(link.contents[0])) for link in xml_keys if str(link.contents[0]).endswith('.zip')]\n",
    "    return files\n",
    "\n",
    "def download_file(url, download_dir=\"/workspaces/data-engineering-zoomcamp-projects/2-docker_terraform/data/citibike_data\"):\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    file_name = os.path.join(download_dir, os.path.basename(url))\n",
    "    subprocess.run([\"wget\", \"-q\", \"-O\", file_name, url], check=True)\n",
    "    return file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98e78b37-ffef-4966-a9ae-f9e1d278b75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/tripdata/JC-202508-citibike-tripdata.csv.zip\n",
      "Downloading https://s3.amazonaws.com/tripdata/JC-202508-citibike-tripdata.csv.zip\n"
     ]
    }
   ],
   "source": [
    "files_list = scrape_citibike_files()\n",
    "\n",
    "for url in files_list[-1:]:\n",
    "    print(url)\n",
    "    print(f\"Downloading {url}\")\n",
    "    download_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a084cc85-fa11-4849-b6af-5c8cc626db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def upload_to_gcs(bucket_name, local_path, gcs_path):\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob(gcs_path)\n",
    "    blob.upload_from_filename(local_path)\n",
    "    print(f\"Uploaded {local_path} to gs://{bucket_name}/{gcs_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b689b3-b7a9-48af-8842-779df795f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/workspaces/data-engineering-zoomcamp-projects/2-docker_terraform/data/citibike_data/JC-202508-citibike-tripdata.csv.zip\"\n",
    "# citibike_data_202508 = pd.read_csv(path, nrows=100, parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "citibike_data_202508 = pd.read_csv(path, nrows=100, parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "citibike_data_202508.head()# Convert columns to appropriate types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a5607-1450-4e55-857d-3edaa6277b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to appropriate types\n",
    "\"\"\"datetime_columns = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"]\n",
    "integer_columns = [\"payment_type\", \"RatecodeID\", \"VendorID\", \"passenger_count\"]\n",
    "\n",
    "\n",
    "for col in datetime_columns:\n",
    "    ny_taxi_data_2016[col] = pd.to_datetime(ny_taxi_data_2016[col])\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d5337-c1b2-42f3-957c-58864c58bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"postgresql://root:root@localhost:5432/ny_taxi\")\n",
    "db_connection = engine.connect()\n",
    "db_connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65382b0-a37b-41a8-95a7-92cb108155c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pd.io.sql.get_schema(ny_taxi_data_2016, name=\"yellow_taxi_data\", con=db_connection)\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a2df05-37af-4d34-b5c7-68df00a6dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator from the large dataset\n",
    "df_iter = pd.read_csv(path, iterator=True, chunksize=100000, parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"])\n",
    "df = next(df_iter)\n",
    "\n",
    "# Create schema in psql database\n",
    "df.head(n=0).to_sql(name=\"yellow_taxi_data\", con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4ef85-0cac-49dc-99e4-d2610f179203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "while True:\n",
    "    start_time = time()\n",
    "    \n",
    "    df = next(df_iter)\n",
    "    df.to_sql(name=\"yellow_taxi_data\", con=engine, if_exists=\"append\")\n",
    "\n",
    "    end_time = time()\n",
    "\n",
    "    print(f'inserted another chunk, ops took {(end_time-start_time):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
